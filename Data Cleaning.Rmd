---
title: <center><strong>Data Cleaning Strategies</strong></center>
author: <center><strong><h1>[Shelmith Nyagathiri Kariuki](https://github.com/Shelmith-Kariuki)</h1></strong></center>
date: <center><strong><h2>March 26, 2020</h2></strong></center>
output:
  html_document:
    toc: yes
    toc_depth: '6'
  pdf_document:
    toc: yes
    toc_depth: '6'
  word_document:
    toc: yes
    toc_depth: '6'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=F, message=FALSE}
library(tidyverse)
```

Incorrect or inconsistent data leads to false conclusions. And so, how well you clean and understand the data has a high impact on the quality of the results.

Two examples of how lack of cleaning data can be costly.

 > The government may want to analyze population census figures to decide which regions require further spending and investment on infrastructure and services. In this case, it will be important to have access to reliable data to avoid erroneous fiscal decisions.

 > In the business world, incorrect data can be costly. Many companies use customer information databases that record data like contact information, addresses, and preferences. For instance, if the addresses are inconsistent, the company will suffer the cost of resending mail or even losing customers.

Data cleaning involves different techniques based on the problem and the data type.

#### 1. Irrelevant data

Irrelevant data are those that are not actually needed, and don’t fit under the context of the problem we’re trying to solve.

Data such as names, email addresses and phone numbers can be irrelevant to the study at hand. 

```{r}
## 150 variables

# df <- df %>% 
#   select(-var1, -var2, -var3)

```


#### 2. Duplicates

Duplicates normally occur in the following instances:

+ Data are combined from different sources

+ The user may hit submit button twice thinking the form wasn’t actually submitted.

A common scenario is when two users have the same identity number, and therefore, they simply should be removed.

```{r}
firstname <- c("Shelmith", "Shelmith","Caren","Caren")
age <- rep(c(20,25),2)
gender <- "Female"

df <- data.frame(firstname, gender, age)

df31 <- df %>% 
  unique()

df1 <- df %>% 
  distinct(firstname, .keep_all = TRUE)

firstname <- c("Shelmith", "Shelmith","Caren","Caren")
age <- c(20,20,25,25)
gender <- "Female"

df2 <- data.frame(firstname, gender, age)


df32 <- df2 %>% 
  unique()
```

#### 3. Data type constraints

Make sure numbers are stored as numerical data types and dates as dates. 

NB: Values that can’t be converted to the specified type will be converted to NA value (or any), with a warning being displayed. This indicates the value is incorrect and must be fixed

```{r}
df <- rChambua::wafanyikazi

df <- df %>% 
  mutate(gender2 = as.character(Gender),
         gender3 = as.numeric(gender2),
         gender4 = as.numeric(Gender))
```

#### 4. Range Constraints
Typically, numbers or dates should fall within a certain range. That is, they have minimum and/or maximum permissible values.

```{r}

```


#### 5. Mandatory Constraints
Certain columns cannot be empty.

```{r}

```

#### 6. Unique Constraints: 

A field, or a combination of fields, must be unique across a dataset. For example, no two persons can have the same social security number.

```{r}
length(unique(df$Sid))

```

#### 7. Uniformity

This is the degree to which a set data measures are specified using the same units of measure in all systems ( see also Unit of measure).
In datasets pooled from different locales, weight may be recorded either in pounds or kilos and must be converted to a single measure using an arithmetic transformation.

```{r}


```


#### 8. Remove white spaces

Extra white spaces at the begining or end of strings should be removed.

```{r}
name1 <- "Shelmith "
name2 <- "Shelmith"
name3 <- " Shelmith"

#names_df <- tibble(names = c(name1, name2, name3))
names_df <- data.frame(names = c(name1, name2, name3))
names_df

names_df <- names_df %>% 
  mutate(checker = ifelse(names == "Shelmith", TRUE, FALSE))


names_df <- names_df %>% 
  mutate(names2 = trimws(names)) %>% 
  mutate(checker2 = ifelse(names2 == "Shelmith", TRUE, FALSE),
         checker3 = ifelse(names %in% grep("Shelmith", names, value = T, ignore.case = T),TRUE,FALSE))

## stringr::str_trim()

```

```{r}
name1 = "Shel"
name2 = "Caren "         
name3 = " Eve"            
names = data.frame(majina = c(name1, name2, name3))

names <- names %>% 
  mutate(majina2 = trimws(majina))

names <- names %>% 
  mutate(checker = ifelse(majina == "Eve", TRUE, FALSE),
         checker2 = ifelse(majina %in% grep("Eve", majina, value = TRUE, ignore.case = T),TRUE,FALSE))
  
```

#### 9. Fix typos

> A bar plot is useful to visualize all the unique values. One can notice some values are different but do mean the same thing i.e. “information_technology” and “IT”. Or, perhaps, the difference is just in the capitalization i.e. “other” and “Other”.

m, Male, fem, FemalE, Femle

```{r}
x <- c("m", "Male", "fem", "FemalE", "Femle")
x <- ifelse(x == "m", "male" ,x)

y <- ifelse(x %in% grep("fem|FemalE|Femle", x, value = T,ignore.case = T),
            "Female", "Male")
y

# z <- ifelse(x %in% grep("Male", x, value = T,ignore.case =T),
#             "Male", "Female")
# z
```

> Watch out for values like “0”, “Not Applicable”, “NA”, “None”, “Null”, or “INF”, they might mean the same thing: The value is missing.

#### 10. Missing values 

These can be dropped, imputed

```{r}

## Read about how to deal with Missing values
```

#### 11. Outliers

They are values that are significantly different from all other observations. Any data value that lies more than (1.5 * IQR) away from the Q1 and Q3 quartiles is considered an outlier.
Outliers should not be removed unless there is a good reason for that.
For example, one can notice some weird, suspicious values that are unlikely to happen, and so decides to remove them. Though, they worth investigating before removing.

```{r}

## Read about how to deal with Outliers
## Check out the ouliers package
```

#### 12. Recording errors

e.g A child being married
Someone says they have children, but then when asked how many , they say 0.
A guy who's had his last monthly period.
a child below 18 years and highest level of education is phd 

```{r}

```

#### 13. Completeness

This is the degree to which all required measures are known. Incompleteness is almost impossible to fix with data cleansing methodology: one cannot infer facts that were not captured when the data in question was initially recorded. (In some contexts, e.g., interview data, it may be possible to fix incompleteness by going back to the original source of data, i.e. re-interviewing the subject, but even this does not guarantee success because of problems of recall - e.g., in an interview to gather data on food consumption, no one is likely to remember exactly what one ate six months ago. In the case of systems that insist certain columns should not be empty, one may work around the problem by designating a value that indicates "unknown" or "missing", but the supplying of default values does not imply that the data has been made complete.)

```{r, message=FALSE, warning=FALSE, fig.width=12,fig.height=8}

```

#### 14.Consistency

This is the degree to which a set of measures are equivalent in across systems (see also Consistency). 

Inconsistency occurs when two data items in the data set contradict each other: e.g., a customer is recorded in two different systems as having two different current addresses, and only one of them can be correct. Fixing inconsistency is not always possible: it requires a variety of strategies - e.g., deciding which data were recorded more recently, which data source is likely to be most reliable (the latter knowledge may be specific to a given organization), or simply trying to find the truth by testing both data items (e.g., calling up the customer).

```{r}

```


